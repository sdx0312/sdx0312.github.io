---
layout:     post
title:      ELK学习笔记
subtitle:   elasticsearch
date:       2019-08-11
author:     BY
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - ELK
---

# ELK学习笔记

## elasticsearch

### elastacsearch集群搭建（基于6.x）

#### 1.安装前环境准备：安装JDK1.8以上版本并配置好环境变量

下载tar包，放在/usr/local路径下：

```
tar -zxvf elasticsearch-6.6.1.tar.gz 解压
mkdir elk 创建elk文件夹
mv elasticsearch-6.6.1 /usr/local/elk/elasticsearch 重命名并移动
mkdir /usr/local/elk/elasticsearch/data 创建存放数据路径
```

------

#### 2.添加用户，非root用户才能正常启动

```
useradd elk 创建一个elk用户
chown -R elk:elk /usr/local/elk/elasticsearch 赋予文件夹权限
```

------

#### 3.yml配置文件

```
vi /usr/local/elk/elasticsearch/config/elasticsearch.yml 更改配置
更改内容如下：
cluster.name: esTest6.6 集群名称
node.name: node173 节点名称，最好在后面加上能标识IP地址的信息
path.data: /usr/local/elk/elasticsearch/data 设置数据存放路径
path.logs: /usr/local/elk/elasticsearch/logs 设置日志存放路径
bootstrap.memory_lock: true 设置为true来锁住内存
network.host: 0.0.0.0 绑定的ip地址：这里是为了便于测试，生产环境配置指定ip
http.port: 9200 设置对外服务的端口
transport.tcp.port: 9300 设置节点间监护的tcp端口
自动集群配置
discovery.zen.ping.unicast.hosts: ["192.100.1.171:9300","192.100.1.172:9300","192.100.1.173:9300"]
这里设置为2，如果不配置，遭受网络故障的集群就有可能将集群分成两个独立的集群
discovery.zen.minimummasternodes: 2
修改完可以查看具体修改了哪些值：
grep '^[a-z]' /usr/local/elk/elasticsearch/config/elasticsearch.yml
```

------

#### 4.调整JVM内存

```
vi /usr/local/elk/elasticsearch/config/jvm.options
默认是1g官方建议对jvm进行一些修改，不然很容易出现OOM,参考官网改参数配置最好不要超过内存的50%，网上资料的说法是设成内存的一半即可，但不要超过32G。
-Xms15g
-Xmx15g
```

------

#### 5.预先设置（新装机器需要设置，不然后续会报错）

**需要修改的内容如下：**

```
vi /etc/security/limits.conf
* soft nofile 65536
* hard nofile 65536
* soft nproc 2048
* hard nproc 4096
#选择锁住swapping
elk soft memlock unlimited
elk hard memlock unlimited
系统配置文件中，修改内容如下：
vi /etc/sysctl.conf
vm.maxmapcount=655360
fs.file-max=655360
注意：修改完执行 sysctl -p 使系统配置生效(使用root用户)
```

#### 6.跨域访问需要在elasticsearch配置文件中加入三条配置，这样才能被head插件识别到（用于测试）：(谷歌浏览器自带插件不用解决跨域问题)

```
vim /usr/local/elk/elasticsearch/config/elasticsearch.yml
http.cors.enabled: true
http.cors.allow-origin: "*"
http.cors.allow-credentials: true
```

------

#### 7.后台启动命令

切换用户为elk，执行下面后台启动命令

/usr/local/elk/elasticsearch/bin/elasticsearch -d

其他两台节点按照上述步骤依次配置启动即可

## 安装cerebro要点

一款Elasticsearch监控工具

非常方便，下载tar包，开箱即用

访问9000端口到达开始界面

## 安装elasticsearch-head要点（建议使*用 cerebro* ）

个人主机安装，便于查看集群状况并支持http测试（安装繁琐，受网络限制较大）

下载地址：<https://github.com/mobz/elasticsearch-head>

1.安装node.js

2.安装grunt 在nodejs根目录下执行

npm install -g grunt -cli

3.安装pathomjs

进入elasticsearch-head根目录下执行命令

npm install

4.运行head

在head根目录下执行

grunt server

启动后访问本机9100端口即可

## 安装分词器 IK 要点

自带的分词器对于中文的支持并不是很好，建议安装IK分词器

<https://github.com/medcl/elasticsearch-analysis-ik/releases> 找到对应的6.6.1版本

下载第一个zip包，放入/usr/local/elk/elasticsearch/plugins/ik 文件夹中

直接解压缩，再重启节点即可

### elastacsearch集群搭建（基于7.x）

7.x改动地方：

```yml
自动集群配置
discovery.seed_hosts: ["192.100.3.20", "192.100.3.24","192.100.3.25"]
cluster.initial_master_nodes: ["192.100.3.20", "192.100.3.24","192.100.3.25"]
gateway.recover_after_nodes: 3
```

## logstash

### logstash单数据源配置

```
10:31:44.984 [main] DEBUG com.example.logback.HelloWorld1 - {"name":"Norman","email":"norman@futurestud.io","isDeveloper":true,"age":26,"userAddress":{"street":"Main Street","houseNumber":"42A","city":"Magdeburg","country":"Germany"}}
```

具体代码实现：

```logstash
input {
    beats {
        port => "5044"
    }
}
filter{
	mutate{
		split => ["message", "-"]   #日志以"-"分割
		add_field => {
			"head" => "%{[message][0]}"
		}
		add_field => {
			"body" => "%{[message][1]}"
		}
		remove_field => ["message"]
		}
		grok {
			 match => { "head" => "%{GREEDYDATA:time} \[%{GREEDYDATA:method}\] %{GREEDYDATA:type} %{GREEDYDATA:classpath}" }  #解析存在问题
		}
    json{
        source => "body"
        target => "doc"
		remove_field => ["body"]
        }
		
}
output {
    elasticsearch {
        hosts => [ "192.100.3.24:9200" ]
		index => "es-%{+YYYY.MM.dd}"
    }
}

```

### output中取字段拼接索引

```
output {
		elasticsearch {
        hosts => [ "192.100.3.24:9200" ]
		index => "%{[doc][logInfo]}-%{+YYYY-MM-dd}"
    }
}
```

**notice:取出的字段是按照输出结果取的**

输出结果代码：

```
{
"_index": "kafka-2019-07-03",
"_type": "_doc",
"_id": "8R97t2sBGrWVAO6RsICJ",
"_version": 1,
"_score": 1,
"_source": {
"@version": "1",
"classpath": " com.logtest.demo.demo2testclass.Demo2Test ",
"log_level": "ERROR ",
"myid": "kafka",
"type": "bhy",
"@timestamp": "2019-07-03T11:00:34.511Z",
"method": "main",
"time": "18:56:18.680",
"doc": {
"eventContent": {
"birthday": "Jul 3, 2019 6:56:18 PM",
"name": "伊24",
"email": "592712515@qq.com",
"age": 24
},
"eventDescription": "事件描述user类测试",
"date": "Jul 3, 2019 6:56:18 PM",
"result": "事件结果测试成功",
"mainIdentity": "主体信息伊格田发送信息",
"event": "BUSSINESS_EVENT",
"logInfo": "event"
}
}
}
```

### logstash多数据源配置

具体代码实现：

```logstash
input {
    beats {
	   add_field => {"myid"=>"es"}
	   host => "127.0.0.0"
        port => "5044"
    }
	 beats {
	   add_field => {"myid"=>"es1"}
	   host => "127.0.0.0"
        port => "5043"
    }
	tcp {
		add_field => {"myid"=>"log4j2"}
		port => "5045"
		codec => json #格式化json
	}
}
filter{
   if [myid] == "es" {
		mutate{
		split => ["message", "-"]
		add_field => {
			"head" => "%{[message][0]}"
		}
		add_field => {
			"body" => "%{[message][1]}"
		}
		remove_field => ["message"]
		}
		grok {
			 match => { "head" => "%{GREEDYDATA:time} \[%{GREEDYDATA:method}\] %{GREEDYDATA:type} %{GREEDYDATA:classpath}" }
		}
    json{
        source => "body"
        target => "doc"
		remove_field => ["body"]
        }
   }
	
		
}
output {
	if [myid] == "es" {
	elasticsearch {
        hosts => [ "192.100.3.24:9200" ]
		index => "es-%{+YYYY.MM.dd}"
    }
	}
	if [myid] == "es1" {
		elasticsearch {
        hosts => [ "192.100.3.24:9200" ]
		index => "es1-%{+YYYY.MM.dd}"
    }
  }
   
}

```

### logstash启动

```
bin/logstash -f first-pipeline.conf --config.test_and_exit
```

（画外音：--config.test_and_exit选项的意思是解析配置文件并报告任何错误）

```
bin/logstash -f first-pipeline.conf --config.reload.automatic
```

（画外音：--config.reload.automatic选项的意思是启用自动配置加载，以至于每次你修改完配置文件以后无需停止然后重启Logstash）

## filebeat

### 配置文件相关：

```
#=========================== Filebeat inputs =============================

filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/usr/logstash-tutorial.log #日志收集路径
#----------------------------- Logstash output --------------------------------
output.logstash:
  hosts: ["192.100.2.37:5044"]  #日志输出路径,输出到logstash （可以直接输出到es）
```

### 启动filebeat

在你保存完以后，因为你已经启动了自动加载配置，所以你不需要重启Logstash来应用你的修改。但是，你确实需要强制Filebeat从头读取日志文件。为了这样做，你需要在终端先按下Ctrl+C停掉Filebeat，然后删除Filebeat注册文件。例如：

```
rm data/registr
```

然后重启Filebeat

```
./filebeat -e -c filebeat.yml -d "publish"
```
## curator

### **1、痛点**

Elasticsearch集群管理中索引的管理非常重要。

数据量少的时候，一个或者几个索引就能满足问题。

但是一旦数据量每天几TB甚至几十TB的增长时，索引的生命周期管理显得尤为重要。

`痛点1`：你是否遇到过磁盘不够，要删除几个月前甚至更早时间数据的情况？

如果没有基于时间创建索引，单一索引借助delete_by_query结合时间戳，会越删磁盘空间越紧张，以至于对自己都产生了怀疑？

`痛点2`：你是否还在通过复杂的脚本管理索引？

1个增量rollover动态更新脚本， 1个定期delete脚本， 1个定期force_merge脚本， 1个定期shrink脚本， 1个定期快照脚本。

索引多了或者集群规模大了，脚本的维护是一笔不菲的开销。

如果以上痛点，你都遇到过了。

那么，客官别走，本文利器curator会给你答案。

### **2、curator是什么？**

![img](https://ask.qcloudimg.com/http-save/yehe-1390885/th4tihj1mt.jpeg?imageView2/2/w/1620)

#### **2.1 被Elastic收编的历史**

curator最早被称为clearESindices.py。 它的唯一功能是删除索引， 而后重命名：logstash_index_cleaner.py。它在logstash存储库下作用：过期日志清理。

此后不久，原作者加入Elastic，它成为了Elasticsearch Curator， Git地址：https://github.com/elastic/curator

#### **2.2 收编后功能强大**

curator允许对索引和快照执行许多不同的操作，包括：

> 

1. 从别名添加或删除索引（或两者！）
2. 更改分片路由分配更改分片路由分配
3. 关闭索引关闭索引
4. 创建索引创建索引
5. 删除索引删除索引
6. 删除快照删除快照
7. 打开被关闭的索引打开被关闭的索引
8. 对索引执行forcemerge段合并操作对索引执行forcemerge段合并操作
9. reindex索引，包括来自远程集群的索引reindex索引，包括来自远程集群的索引
10. 更改索引的每个分片的副本数 更改索引的每个分片的副本数
11. rollover索引rollover索引
12. 生成索引的快照（备份）生成索引的快照（备份）
13. 还原快照还原快照

### **3、curator 版本**

不同于Elasticsearch甚至ELKB的版本统一规范，curator有自己的一套版本规范。 

![img](https://ask.qcloudimg.com/http-save/yehe-1390885/8p9qk2mia2.png?imageView2/2/w/1620)

简化记录如下：  6.XES使用 curator 5； 5.XES可以使用curator5 或者 curator4 ，

具体参考官网：http://t.cn/EGi2nLX

还等什么，赶紧用起来！

### **4、Curator使用指南**

#### **4.1 curator安装**

curator可以通过多种方式安装，具体取决于您的需求。

值得注意的是，Curator只需要安装在可访问Elasticsearch集群中机器上就可以运行。 它不需要安装在群集中的一个节点上。

我的机器是5.X版本，使用如下操作ok。

**Step1：安装：**

```
1pip install elasticsearch-curator
```

centos6/7用户更简洁：

```
1yum install elasticsearch-curator
```

**Step 2：升级至最新版本（非必须，根据自己需要）：**

```
1pip install -U elasticsearch-curator
```

验证执行成功方法1：

```
1curator_cli show_indices
```

若成功，会显示索引信息。

#### **4.2 curator用法讲解**

##### **4.2.1 用法1：curator_cli 命令行**

用法举例：curator_cli 关闭全部一天前创建的索引名称为logs_*开头的索引。

```
1curator_cli --host 192.168.1.2 --port 9200 close --filter_list '[{"filtertype":"age","source":"creation_date","direction":"older","unit":"days","unit_count":1},{"filtertype":"pattern","kind":"prefix","value":"logs_"}]'
```

`好处`：无需配置文件，一行命令即可成功。 `坏处`：不能便捷的适应复杂的操作。

##### **4.2.2 用法2：curator命令行**

用法举例：

```
1curator [--config CONFIG.YML] [--dry-run] ACTION_FILE.YML
```

解释： 1、CONFIG.YML是配置文件，用于配置ES集群信息。 CONFIG.YML样例：

```
1[root@localhost .curator]# cat curator.yml 
 2# Remember, leave a key empty if there is no value.  None will be a string,
 3## not a Python "NoneType"
 4
 5client:
 6  hosts: 192.168.1.1
 7  port: 9200
 8  url_prefix:
 9  use_ssl: False
10  certificate:
11  client_cert:
12  client_key:
13  ssl_no_validate: False
14  http_auth:
15  timeout: 30
16  master_only: False
17
18logging:
19  loglevel: INFO
20  logfile: /home/curator/logs
21  logformat: default
22  blacklist: ['elasticsearch', 'urllib3']
```

核心配置：

> 1）集群IP；  2）安全认证信息；  3）日志信息。

2、ACTION_FILE.YML 执行索引操作的配置信息 由于支持的操作非常多，建议直接参考官网配置即可：

> http://t.cn/EGiLwyk http://t.cn/EGiL4EF

拿删除历史索引举例：

以下命令删除了30天前，以logs_*开头的索引。

```
 1[root@localhost .curator]# cat action.yml 
 2---
 3# Remember, leave a key empty if there is no value.  None will be a string,
 4# not a Python "NoneType"
 5#
 6# Also remember that all examples have 'disable_action' set to True.  If you
 7# want to use this action as a template, be sure to set this to False after
 8# copying it.
 9actions:
10  1:
11    action: delete_indices
12    description: >-
13      Delete indices older than 20 days (based on index name), for logstash-
14      prefixed indices. Ignore the error if the filter does not result in an
15      actionable list of indices (ignore_empty_list) and exit cleanly.
16    options:
17      ignore_empty_list: True
18      disable_action: False
19    filters:
20    - filtertype: pattern
21      kind: prefix
22      value: logs_
23    - filtertype: age
24      source: name
25      direction: older
26      timestring: '%Y.%m.%d'
27      unit: days
28      unit_count: 30
```

如果执行多个任务怎么办呢？

注意：actions: 后面的，`依次类推`：

> 2：执行操作  3：执行操作  4：执行操作  N：执行操作

好处：1个配置搞定10+处操作，不费劲！

#### **4.3 curator 实践**

经过4.2的配置，实践执行如下：

curator --config config.yml   指定路径/action.yml

#### **4.4 周期性执行**

借助crontab，每天零点5分执行

```
1$ crontab -e
```

加上如下的命令：

```
15 0 * * * curator --config config.yml action.yml
```

### **5、小结**

- **切记：** curator适用于`基于时间或者template其他方式创建的索引`， **不适合单一索引存储N久历史数据的操作的场景**。
- **思考：** 遇到通用问题，不要重复造轮子，看看官方或者别人是否已经实现了，已经有更好的方案了。 如果有，就“拿来主义”，和自己业务不一致，可以考虑优化。 比如：类似curator，有很多公司已经进一步加工为可视化工具，极大提高效率。